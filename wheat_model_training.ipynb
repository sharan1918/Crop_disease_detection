{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŒ¾ Wheat Disease Detection - Model Training\n",
        "**Classes:** Healthy | Unhealthy (Smut, Yellow Rust) | Others\n",
        "\n",
        "**Architecture:** ResNet50 Transfer Learning (2-Phase Training)\n",
        "\n",
        "## Instructions:\n",
        "1. Upload `Wheat.zip` to your Google Drive or directly to Colab.\n",
        "2. Run all cells in order.\n",
        "3. After training, **download** `wheat_disease_model.h5` and `wheat_class_indices.json`.\n",
        "4. Place both files into your project's `Ml_Models/` folder."
      ],
      "metadata": {
        "id": "wheat_intro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# CELL 1: Install Dependencies\n",
        "# ================================================\n",
        "!pip install opencv-python tensorflow\n"
      ],
      "metadata": {
        "id": "wheat_install"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# CELL 2: Import Libraries\n",
        "# ================================================\n",
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"All libraries imported successfully!\")\n",
        "print(\"TensorFlow Version:\", tf.__version__)\n"
      ],
      "metadata": {
        "id": "wheat_imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# CELL 3: Upload and Extract Dataset\n",
        "# ================================================\n",
        "# Option A: If you uploaded Wheat.zip directly to Colab runtime:\n",
        "!unzip -q /content/Wheat.zip -d /content/\n",
        "print(\"Folder extracted successfully!\")\n"
      ],
      "metadata": {
        "id": "wheat_extract"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# CELL 4: Verify Dataset Structure\n",
        "# ================================================\n",
        "!ls /content/wheat\n",
        "print(\"\\n--- Healthy folder ---\")\n",
        "!ls /content/wheat/Healthy | wc -l\n",
        "print(\"\\n--- Others folder ---\")\n",
        "!ls /content/wheat/Others | wc -l\n",
        "print(\"\\n--- Unhealthy folder (sub-classes) ---\")\n",
        "!ls /content/wheat/Unhealthy\n"
      ],
      "metadata": {
        "id": "wheat_verify"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# CELL 5: Configuration\n",
        "# ================================================\n",
        "\n",
        "# Where your data is located after unzipping\n",
        "DATA_DIR = '/content/wheat'\n",
        "\n",
        "# Where to save the finished model and mapping file\n",
        "MODEL_SAVE_PATH = '/content/wheat_disease_model.h5'\n",
        "MAPPING_SAVE_PATH = '/content/wheat_class_indices.json'\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS_PHASE_1 = 15\n",
        "EPOCHS_PHASE_2 = 20\n",
        "\n",
        "print(\"Configuration set!\")\n",
        "print(f\"Data directory : {DATA_DIR}\")\n",
        "print(f\"Model will be saved to: {MODEL_SAVE_PATH}\")\n",
        "print(f\"Class mapping will be saved to: {MAPPING_SAVE_PATH}\")\n"
      ],
      "metadata": {
        "id": "wheat_config"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# CELL 6: Load Images into Memory\n",
        "# ================================================\n",
        "print(\"Loading images into memory...\")\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "class_names = []\n",
        "\n",
        "# ================================\n",
        "# SET YOUR LIMIT HERE\n",
        "# ================================\n",
        "MAX_IMAGES_PER_CLASS = 1100\n",
        "\n",
        "def load_folder(folder_path, class_name):\n",
        "    if not os.path.exists(folder_path): return\n",
        "    if class_name not in class_names:\n",
        "        class_names.append(class_name)\n",
        "    class_idx = class_names.index(class_name)\n",
        "\n",
        "    loaded_count = 0\n",
        "    skipped_count = 0\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        # Stop loading if we hit the limit\n",
        "        if loaded_count >= MAX_IMAGES_PER_CLASS:\n",
        "            skipped_count += 1\n",
        "            continue\n",
        "\n",
        "        if filename.endswith(('.png', '.jpg', '.jpeg', '.JPG')):\n",
        "            img_path = os.path.join(folder_path, filename)\n",
        "            try:\n",
        "                img = cv2.imread(img_path)\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                img = cv2.resize(img, IMG_SIZE)\n",
        "                images.append(img)\n",
        "                labels.append(class_idx)\n",
        "                loaded_count += 1\n",
        "            except Exception as e:\n",
        "                print(f\"Error reading {img_path}: {e}\")\n",
        "\n",
        "    print(f\"[{class_name}] Loaded: {loaded_count} images (Skipped: {skipped_count} extra images)\")\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Load Healthy class\n",
        "# -------------------------------------------------\n",
        "load_folder(os.path.join(DATA_DIR, 'Healthy'), 'Healthy')\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Load Others class (non-wheat images)\n",
        "# -------------------------------------------------\n",
        "load_folder(os.path.join(DATA_DIR, 'Others'), 'Others')\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Load Unhealthy sub-classes (Smut, Yellow Rust, etc.)\n",
        "# -------------------------------------------------\n",
        "unhealthy_dir = os.path.join(DATA_DIR, 'Unhealthy')\n",
        "if os.path.exists(unhealthy_dir):\n",
        "    for sub_dir in os.listdir(unhealthy_dir):\n",
        "        path = os.path.join(unhealthy_dir, sub_dir)\n",
        "        if os.path.isdir(path):\n",
        "            load_folder(path, sub_dir)\n",
        "\n",
        "# Convert to Numpy Arrays\n",
        "X = np.array(images)\n",
        "y = np.array(labels)\n",
        "\n",
        "print(f\"\\nSUCCESS: Loaded {len(X)} total images.\")\n",
        "print(f\"Classes Found ({len(class_names)}): {class_names}\")\n"
      ],
      "metadata": {
        "id": "wheat_load"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# CELL 7: Preprocess & Split Data\n",
        "# ================================================\n",
        "print(\"Preprocessing images for ResNet50...\")\n",
        "X = tf.keras.applications.resnet.preprocess_input(X)\n",
        "\n",
        "print(\"Splitting data into Training (80%) and Validation (20%)...\")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training Set: {len(X_train)} images\")\n",
        "print(f\"Validation Set: {len(X_val)} images\")\n",
        "\n",
        "# Handle class imbalance automatically\n",
        "weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weights = dict(enumerate(weights))\n",
        "print(\"Class Weights calculated!\")\n",
        "print(f\"Class Weights: {class_weights}\")\n"
      ],
      "metadata": {
        "id": "wheat_preprocess"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# CELL 8: Build the ResNet50 Transfer Learning Model\n",
        "# ================================================\n",
        "print(\"Building the Transfer Learning Model...\")\n",
        "\n",
        "# Data augmentation block\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.2),\n",
        "    layers.RandomTranslation(0.1, 0.1),\n",
        "])\n",
        "\n",
        "# Load Base Model\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "base_model.trainable = False  # Freeze base layers\n",
        "\n",
        "# Create Top Model\n",
        "inputs = keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = base_model(x, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "outputs = layers.Dense(len(class_names), activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "# Save rules\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=8, restore_best_weights=True, monitor='val_accuracy'),\n",
        "    ModelCheckpoint(MODEL_SAVE_PATH, save_best_only=True, monitor='val_accuracy'),\n",
        "    ReduceLROnPlateau(factor=0.2, patience=3, monitor='val_loss')\n",
        "]\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "wheat_build_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# CELL 9: Phase 1 - Train Custom Head Layers\n",
        "# ================================================\n",
        "print(\"Starting PHASE 1: Training Custom Head Layers\")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(1e-3),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history1 = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=EPOCHS_PHASE_1,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weights\n",
        ")\n"
      ],
      "metadata": {
        "id": "wheat_phase1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# CELL 10: Phase 2 - Fine-Tune Top 30 Layers\n",
        "# ================================================\n",
        "print(\"Starting PHASE 2: Fine-Tuning Top 30 Layers\")\n",
        "\n",
        "# Unfreeze the base model\n",
        "base_model.trainable = True\n",
        "\n",
        "# Refreeze all layers except the top 30\n",
        "for layer in base_model.layers[:-30]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Recompile with a MUCH LOWER learning rate\n",
        "model.compile(\n",
        "    optimizer=Adam(1e-5),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history2 = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=EPOCHS_PHASE_2,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weights\n",
        ")\n"
      ],
      "metadata": {
        "id": "wheat_phase2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# CELL 11: Save Results & Plot Training Curves\n",
        "# ================================================\n",
        "\n",
        "# Save the mapping file so your Flask app knows which index is which class\n",
        "class_mapping = {name: int(idx) for idx, name in enumerate(class_names)}\n",
        "class_mapping_inverted = {int(idx): name for idx, name in enumerate(class_names)}\n",
        "\n",
        "with open(MAPPING_SAVE_PATH, 'w') as f:\n",
        "    json.dump(class_mapping, f)\n",
        "\n",
        "print(\"\\n--- TRAINING COMPLETE ---\")\n",
        "print(f\"Model saved to: {MODEL_SAVE_PATH}\")\n",
        "print(f\"Mapping saved to: {MAPPING_SAVE_PATH}\")\n",
        "print(f\"Your App Classes: {class_mapping_inverted}\")\n",
        "\n",
        "# Plotting\n",
        "acc = history1.history['accuracy'] + history2.history['accuracy']\n",
        "val_acc = history1.history['val_accuracy'] + history2.history['val_accuracy']\n",
        "loss = history1.history['loss'] + history2.history['loss']\n",
        "val_loss = history1.history['val_loss'] + history2.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label='Training Acc')\n",
        "plt.plot(val_acc, label='Validation Acc')\n",
        "plt.axvline(x=EPOCHS_PHASE_1, color='red', linestyle='--', label='Fine-Tuning Starts')\n",
        "plt.legend()\n",
        "plt.title('Wheat Model - Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.axvline(x=EPOCHS_PHASE_1, color='red', linestyle='--', label='Fine-Tuning Starts')\n",
        "plt.legend()\n",
        "plt.title('Wheat Model - Loss')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wheat_save_plot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# CELL 12: Download Model Files\n",
        "# ================================================\n",
        "# Download both files to your local machine\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Downloading wheat_disease_model.h5 ...\")\n",
        "files.download(MODEL_SAVE_PATH)\n",
        "\n",
        "print(\"Downloading wheat_class_indices.json ...\")\n",
        "files.download(MAPPING_SAVE_PATH)\n",
        "\n",
        "print(\"\\nDone! Place both files in your project's Ml_Models/ folder.\")\n"
      ],
      "metadata": {
        "id": "wheat_download"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
