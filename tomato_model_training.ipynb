{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# \ud83c\udf45 Tomato Disease Detection - Professional Training Notebook\n",
                "This notebook trains a ResNet50 model on 20,000 images (5,000 per class).\n",
                "\n",
                "**Classes:** Healthy, Others, Leaf Blight, Bacterial Spot"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Install dependencies\n",
                "!pip install -q opencv-python tensorflow tqdm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Imports\n",
                "import os\n",
                "import numpy as np\n",
                "import tensorflow as tf\n",
                "import cv2\n",
                "from google.colab import drive, files\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "from tensorflow.keras.applications import ResNet50\n",
                "from tensorflow.keras import layers, models\n",
                "import shutil\n",
                "import json"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Connect Drive & Extract\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "# Install 7-Zip for fast extraction\n",
                "!apt-get install -y p7zip-full\n",
                "\n",
                "print(\"Copying tomato.7z from Drive... (This might take a minute)\")\n",
                "!cp /content/drive/MyDrive/tomato.7z /content/tomato.7z\n",
                "\n",
                "print(\"Extracting dataset... (20k images)\")\n",
                "!7z x /content/tomato.7z -o/content/ -y\n",
                "\n",
                "print(\"\\n\u2705 Folder extracted successfully!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Configuration\n",
                "DATA_DIR = '/content/tomato'\n",
                "MODEL_SAVE_PATH = '/content/tomato_disease_model.h5'\n",
                "MAPPING_SAVE_PATH = '/content/tomato_class_indices.json'\n",
                "IMG_SIZE = (224, 224)\n",
                "BATCH_SIZE = 32 # Balanced for 16GB RAM\n",
                "\n",
                "# Reorganize folders to flatten Unhealthy children into main classes\n",
                "FINAL_DATA_DIR = '/content/tomato_final'\n",
                "if not os.path.exists(FINAL_DATA_DIR):\n",
                "    os.makedirs(FINAL_DATA_DIR)\n",
                "    # Move Healthy and Others\n",
                "    shutil.copytree(f'{DATA_DIR}/Healthy', f'{FINAL_DATA_DIR}/Healthy')\n",
                "    shutil.copytree(f'{DATA_DIR}/Others', f'{FINAL_DATA_DIR}/Others')\n",
                "    # Move specific unhealthy classes\n",
                "    unhealthy_path = f'{DATA_DIR}/Unhealthy'\n",
                "    folders = [f for f in os.listdir(unhealthy_path) if os.path.isdir(os.path.join(unhealthy_path, f))]\n",
                "    for f in folders:\n",
                "        shutil.copytree(os.path.join(unhealthy_path, f), os.path.join(FINAL_DATA_DIR, f))\n",
                "\n",
                "print(f\"Dataset ready at: {FINAL_DATA_DIR}\")\n",
                "print(\"Classes found:\", os.listdir(FINAL_DATA_DIR))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Data Generators (Memory Efficient)\n",
                "datagen = ImageDataGenerator(\n",
                "    preprocessing_function=tf.keras.applications.resnet.preprocess_input,\n",
                "    validation_split=0.2,\n",
                "    rotation_range=20,\n",
                "    width_shift_range=0.2,\n",
                "    height_shift_range=0.2,\n",
                "    horizontal_flip=True\n",
                ")\n",
                "\n",
                "train_generator = datagen.flow_from_directory(\n",
                "    FINAL_DATA_DIR,\n",
                "    target_size=IMG_SIZE,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    class_mode='categorical',\n",
                "    subset='training'\n",
                ")\n",
                "\n",
                "val_generator = datagen.flow_from_directory(\n",
                "    FINAL_DATA_DIR,\n",
                "    target_size=IMG_SIZE,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    class_mode='categorical',\n",
                "    subset='validation'\n",
                ")\n",
                "\n",
                "class_names = list(train_generator.class_indices.keys())\n",
                "print(f\"\\n\u2705 Success! Dataset contains {train_generator.samples + val_generator.samples} images across {len(class_names)} classes.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6. Build the ResNet50 Model\n",
                "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
                "base_model.trainable = False\n",
                "\n",
                "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
                "x = base_model(inputs, training=False)\n",
                "x = layers.GlobalAveragePooling2D()(x)\n",
                "x = layers.Dropout(0.4)(x)\n",
                "x = layers.Dense(256, activation='relu')(x)\n",
                "x = layers.Dropout(0.4)(x)\n",
                "outputs = layers.Dense(len(class_names), activation='softmax')(x)\n",
                "\n",
                "model = models.Model(inputs, outputs)\n",
                "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 7. Phase 1: Train Head Layers\n",
                "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
                "\n",
                "callbacks = [\n",
                "    EarlyStopping(patience=5, restore_best_weights=True, monitor='val_accuracy'),\n",
                "    ModelCheckpoint(MODEL_SAVE_PATH, save_best_only=True, monitor='val_accuracy'),\n",
                "    ReduceLROnPlateau(factor=0.2, patience=3, monitor='val_loss')\n",
                "]\n",
                "\n",
                "print(\"Starting PHASE 1...\")\n",
                "history1 = model.fit(train_generator, validation_data=val_generator, epochs=15, callbacks=callbacks)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 8. Phase 2: Fine-Tuning\n",
                "print(\"Starting PHASE 2 (Fine-Tuning Top 30 Layers)...\")\n",
                "base_model.trainable = True\n",
                "for layer in base_model.layers[:-30]:\n",
                "    layer.trainable = False\n",
                "\n",
                "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
                "\n",
                "history2 = model.fit(train_generator, validation_data=val_generator, epochs=20, callbacks=callbacks)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 9. Save and Download\n",
                "class_mapping = {name: int(idx) for name, idx in train_generator.class_indices.items()}\n",
                "with open(MAPPING_SAVE_PATH, 'w') as f:\n",
                "    json.dump(class_mapping, f)\n",
                "\n",
                "print(f\"\u2705 Class Mapping: {class_mapping}\")\n",
                "print(\"\ud83d\udce5 Downloading files...\")\n",
                "from google.colab import files\n",
                "files.download(MODEL_SAVE_PATH)\n",
                "files.download(MAPPING_SAVE_PATH)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}